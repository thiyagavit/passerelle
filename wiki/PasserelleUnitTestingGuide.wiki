#summary Introducing the usage of Passerelle's test support tools, for unit-testing actors and simple flows.

= Introduction =

Testing Passerelle models and/or actors can be done manually, by designing and running some test models from one of the available model editors and runtimes. But this is not a scalable approach, nor can it be integrated in automated builds, continuous integration setups etc.

This guide introduces some test features of Passerelle, to support the construction of unit tests that can become part of automated test suites.

= Main goals =

The Passerelle test support tools are oriented towards :
  * Setting up a flow definition in Java code, i.o. requiring a graphical editor
  * Simple way to execute a model from test code, with support for overriding actor parameter values
  * Setting expected counts for messages sent or received by actor ports
  * Setting expected counts for actor fire/process iterations per actor

With these things in place, a wide variety of test scenarios can be implemented.

= Overview of a test case =

The Passerelle test support builds on [http://junit.org/ JUnit]. 
Any kind of JUnit-based test approach could be followed, but we assume a plain usage of JUnit 3 `junit.framework.TestCase` implementations.

Using plain actor constructors combined with the API provided by `com.isencia.passerelle.model.Flow` and `com.isencia.passerelle.model.FlowManager`, it is possible to define
and execute a Passerelle model in code :
  # first a Flow instance must be created, and a Director must be assigned to it
  # then all required actors can be constructed in that Flow
    * the actor parameter configuration can also be done via directly setting parameter values
    * but in most cases it is preferred to set parameter values via so-called "parameter overrides" with the flow execution, later on 
  # the Flow API has several utility methods to connect actor ports
  # the !FlowManager has methods to execute models in blocking and non-blocking ways. 
    * For simple test control, the blocking approach is preferred.
    * For advanced and/or high-volume testing, non-blocking testing may be advisable, exploiting an `ExecutionListener` to be notified when a certain execution has finished.
  # expected test results can be specified and asserted using `com.isencia.passerelle.testsupport.FlowStatisticsAssertion`


= Some examples =